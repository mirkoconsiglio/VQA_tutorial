{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Variational Quantum Algorithms\n",
    "\n",
    "Quantum computing is a relatively young field, which bloomed as an idea to Benioff when he proposed the quantum mechanical analogue of a Turing machine, which was quickly followed up by Deutsch, and Feynman, among many others. Research in quantum computing flourished when Shor devised a quantum algorithm that efficiently determines prime factors of composite integers, which could result in the collapse of many modern cryptographic protocols. Since then, many quantum algorithms have been designed with varying applications, ranging from optimisation, machine learning, quantum many-body physics and chemistry, cryptography, communication and pharmaceuticals.\n",
    "\n",
    "## Computational Complexity Theory in a Nutshell\n",
    "\n",
    "Computational complexity theory is a means of assigning computational problems to different complexity classes, each with its own set of characteristics and limitations in terms of some resource, most commonly time and memory. For the sake of conciseness, the asymptotic notation of function complexity will be briefly described, and only the relevant complexity classes will be mentioned in this thesis. The most important three definitions for asymptotic complexity (as a function the size of the system $n$) are:\n",
    "\n",
    "- $f(n) = \\mathcal{O}(T(n))$, where $f$ is said to be asymptotically bounded above by $T$ (up to a multiplicative constant).\n",
    "- $f(n) = \\Omega(T(n))$, where $f$ is said to be asymptotically bounded below by $T$ (up to a multiplicative constant).\n",
    "- $f(n) = \\Theta(T(n))$, where $f$ is said to be asymptotically bounded above and below by $T$ (up to two multiplicative constants).\n",
    "\n",
    "Now let us turn our attention to complexity classes which are relevant to the algorithms discussed and mentioned in this thesis:\n",
    "- P: problems that can be solved in a polynomial time by a deterministic classical computer. This means that the problem can be solved in $\\mathcal{O}\\left(n^k\\right)~\\exists~k > 0$. Note that $k = 1$ denotes linear time whilst $0 < k < 1$ denotes fractional time.\n",
    "- NP: problems that can be verified in a polynomial time by a deterministic classical computer, but not necessarily solved in such a time. This implies that the problem can be verified in $\\mathcal{O}\\left(n^k\\right)~\\exists~k > 1$, however the solution cannot be determined faster than $\\Omega\\left(n^k\\right)~\\forall~k > 1$.\n",
    "- BQP: stands for Bounded-error Probabilistic Polynomial-time. Essentially equivalent to P but for a quantum computer.\n",
    "- PSPACE: stands for Polynomial Space. Problems that can be solved in a polynomial space by a deterministic classical computer.\n",
    "- EXPTIME: stands for Exponential Time. Problems that can be solved in an exponential time by a deterministic classical computer. This means that the problem can be solved in $\\mathcal{O}\\left(k^n\\right)~\\exists~k > 1$.\n",
    "- QMA: stands for Quantum Merlin--Arthur and is the quantum analogy for $NP$. A problem is said to be in $QMA$ if the solution can be verified in a polynomial time by a quantum computer, if it is given \"yes\" as an answer.\n",
    "\n",
    "The classes mentioned above can be neatly placed in containers as shown in the figure below. Furthermore, the last few important definitions are the concepts of reducibility, hardness and completeness. A problem $A$ is said to be reducible to a problem $B$, if a method for solving $B$ implies a method for solving $A$ in the same time. This is denoted as $A \\leq B$. This can also be interpreted to mean that solving $B$ is at least as hard as solving $A$. Given a complexity class $C$, a problem $X$ is said to be $C$-hard if every problem in $C$ reduces to $X$, and finally, a problem $X$ is said to be $C$-complete if $X$ is $C$-hard and also $X \\in C$.\n",
    "\n",
    "<img height=\"500\" src=\"figures/complexity_classes.png\" width=\"400\"/>\n",
    "\n",
    "A typical example of a BQP problem is integer factorisation, which is polynomially solvable by a quantum computer using Shor's algorithm. On the other hand, there is no known classical algorithm that can factor integers in polynomial time. However, it is crucial to carry out tests for quantum algorithmic complexity, as it is obscure whether quantum computers are able to solve NP-Complete problems in polynomial time. In fact, most of the algorithms which will be discussed in this work are related to the preparation of a desired initial state. It is established that preparing --- and also *finding* specific states, such as ground-states of Hamiltonians --- is QMA-hard.\n",
    "\n",
    "## The Era of Noise. Is there a Solution?\n",
    "\n",
    "While the fault-tolerant quantum computer era might herald in a new age of unparalleled efficiency through quantum algorithms, we are still a far cry away from achieving _true_ quantum advantage. In essence, quantum advantage refers to the ability of quantum computers to solve certain problems significantly faster than classical computers. Formally, it consists of two fundamental tasks: the engineering feat of constructing a robust quantum computer, and the computational complexity challenge of identifying a problem that can be efficiently solved by such a quantum computer, showcasing a superpolynomial speedup compared to the most efficient classical algorithms available for that specific task.\n",
    "\n",
    "Initially, most of the proposed quantum algorithms required millions of physical qubits to operate successfully and efficiently, along with the implementation of quantum error correction (QEC) protocols, to reduce the inherent decoherence of qubits, improper gate control and measurement errors --- collectively known as noise. Currently, we are in the era of noisy intermediate-scale quantum (NISQ) devices, where we only have access to around the order of 100 noisy qubits at most. As a result, most of the current quantum algorithms have to be devised with the current severe limitations in mind. In fact, the main goal in the NISQ era is to develop techniques and algorithms which are able to extract the maximum available quantum computational power, while also being suitable to scale for the future long-term goal of fault-tolerant quantum computation.\n",
    "\n",
    "Nevertheless, attempts at attaining quantum advantage, or quantum supremacy, have been made in the NISQ era. In particular, the main proposals for demonstrating quantum advantage typically fall under one of the following algorithms: factoring integers, notably using Shor's algorithm; boson sampling, a computing paradigm centred on the transmission of identical photons through a linear-optical network can effectively tackle specific sampling and search problems; and cross-entropy benchmarking, which consists of sampling the output distribution of random quantum circuits.\n",
    "\n",
    "For instance, Google claimed to have achieved quantum supremacy in 2019 with its 53-qubit quantum computer, Sycamore, demonstrating that it could solve a specific problem faster than the most powerful classical supercomputers at the time. In response, IBM indicated that certain claims were overstated and proposed a potential time frame of 2.5 days rather than 10,000 years for solving the same problem, detailing various techniques that a classical supercomputer could employ to enhance computational efficiency. IBM's input holds significance, especially considering that the most potent supercomputer at that time, Summit, was developed by IBM. Subsequent to this, researchers have refined algorithms for the sampling problem pivotal in asserting quantum supremacy, leading to significant reductions in the disparity between Google's Sycamore processor and classical supercomputers, even surpassing it in certain instances.\n",
    "\n",
    "In December 2020, researchers from the University of Science and Technology of China, led by Jian-Wei Pan, similarly, claimed to have achieved quantum supremacy by employing Gaussian boson sampling on 76 photons with their photonic quantum computer named Jiuzhang. According to the paper, the quantum computer generated a number of samples in 200 seconds that would necessitate a classical supercomputer 2.5 billion years to compute. In October 2021, researchers from the University of Science and Technology of China once more demonstrated quantum advantage by constructing two supercomputers named Jiuzhang 2.0 and Zuchongzhi. The Jiuzhang 2.0, which operates on light-based principles, employed Gaussian boson sampling to detect 113 photons from a 144-mode optical interferometer, achieving a sampling rate acceleration of 1024 --- representing an advancement of 37 photons and 10 orders of magnitude compared to the previous Jiuzhang system.\n",
    "\n",
    "The current state-of-the-art in experimentation and the growing need for QEC have spurred the development of inventive algorithms aimed at achieving the long-anticipated quantum advantage. The term \"near-term quantum computation\" has been introduced to encompass these quantum algorithms specifically tailored for quantum computing hardware expected to emerge in the coming years. Conversely, NISQ devices can only execute quantum circuits structured according to a specified graph topology, with each node representing qubits and gates typically operating on one or two qubits. Due to the inherent noise in gate operations, NISQ algorithms are inherently limited to shallow depths. It is important to clarify that NISQ is a hardware-centric concept, and does not inherently imply a temporal aspect. Nevertheless, it is important to identify that the term \"near-term\"\" is subjective and varies among researchers, as predictions regarding experimental progress are prone to human biases. Algorithms tailored for \"near-term\" hardware may become infeasible if hardware advancements fail to align with the experimental requirements of the algorithm. Readers interested in understanding better the current quantum technologies and their implementations can refer to [Understanding Quantum Technologies](https://www.oezratty.net/wordpress/2023/understanding-quantum-technologies-2023/).\n",
    "\n",
    "So, what are the means of harnessing the power given by NISQ computers? Since the capacity of a modern quantum computer is limited, many algorithms are devised in a hybrid quantum--classical manner. Such algorithms assign a classically demanding component to a quantum computer, while the tractable part is still carried out on a (sufficiently powerful) classical computer. The concept of these algorithms typically involves some variational updates to parameters in a parametrised quantum circuit (PQC), subsequently termed variational quantum algorithms (VQAs) (which is a subset of hybrid quantum--classical algorithms). Originally, the first two designs for VQAs were: the variational quantum eigensolver (VQE), initially proposed to solve quantum chemistry problems; and the quantujm approximate optimisation algorithm (QAOA), intended to solve combinatorial optimisation problems. Both of these algorithms can be considered as the parents of the entire VQA family.\n",
    "\n",
    "VQAs attempt to bridge the gap between quantum and classical, by leveraging the peak capabilities of current classical computers, and the potential of NISQ and near-term devices to obtain a significant computational advantage. Accounting for all the limitations imposed by NISQ computers necessitates employing either an optimisation-based or learning-based strategy, a task effectively tackled by VQAs. They serve as the quantum counterpart to highly successful machine learning techniques, such as neural networks. Furthermore, VQAs utilise classical optimisation techniques by employing PQCs, which are then optimised by classical optimisers. This method offers the benefit of maintaining a shallow quantum circuit depth, thereby reducing noise, unlike quantum algorithms designed for fault-tolerant systems. VQAs have been extensively explored across a wide array of applications, as illustrated in the figure below, virtually encompassing most of the envisioned uses for quantum computing. While they hold promise as a pathway to achieving quantum advantage in the near term, VQAs encounter significant challenges related to their trainability, accuracy, and efficiency.\n",
    "\n",
    "<img height=\"500\" src=\"figures/applications.png\" width=\"600\"/>\n",
    "\n",
    "## Overview of the Course\n",
    "\n",
    "This course will be a short introduction to Variational Quantum Algorithms (VQAs), through the use of Python and associated packages (namely [Qiskit](https://qiskit.org)).\n",
    "\n",
    "## Programming Environment\n",
    "\n",
    "We will be using Python for this course. The following packages will be necessary: `scipy matplotlib numpy qiskit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "SciPy version: 1.14.1\n",
      "MatPlotLib version: 3.9.2\n",
      "NumPy version: 2.1.0\n",
      "Qiskit version: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys, scipy, matplotlib, numpy, qiskit\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"SciPy version: {scipy.__version__}\")\n",
    "print(f\"MatPlotLib version: {matplotlib.__version__}\")\n",
    "print(f\"NumPy version: {numpy.__version__}\")\n",
    "print(f\"Qiskit version: {qiskit.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\newcommand{\\ket}[1]{\\left|{#1}\\right\\rangle}$$\n",
    "$$\\newcommand{\\bra}[1]{\\left\\langle{#1}\\right|}$$\n",
    "\n",
    "# Building a Variational Quantum Algorithm\n",
    "\n",
    "A VQA is made up of separate modules that can be easily combined, improved and extended according to the developments in quantum technology. The different modules of a VQA are the:\n",
    "\n",
    "1. Objective Function\n",
    "2. Parametrised Quantum Circuit\n",
    "3. Measurement Technique\n",
    "4. Classical Optimiser\n",
    "\n",
    "In this work, the above modules are only briefly discussed in this course for the sake of brevity, further detail on constructing VQAs can be found in [Bharti et al.](https://link.aps.org/doi/10.1103/RevModPhys.94.015004). A diagram of the setup of a VQA can be seen in the figure below.\n",
    "\n",
    "<img height=\"500\" src=\"figures/vqa.png\" width=\"800\"/>\n",
    "\n",
    "The figure above is a diagrammatic representation of a VQA, with the four main modules: **a)** The objective function $O$, which encodes the problem to be solved; **b)** the PQC, in which the parameters $\\boldsymbol{\\theta}$ are variationally updated to minimize the objective function; **c)** the measurement technique, which involves basis changes and measurements needed to compute the objective function; and **d)** the classical optimizer that minimizes the objective function while proposing a new set of variational parameters.\n",
    "\n",
    "## Objective Function\n",
    "\n",
    "When considering a quantum system, the Hamiltonian typically contains all of the relevant information of that system and generally forms its description. In quantum chemistry or many-body physics, the expectation value of the Hamiltonian can lead to the energy of the system, which is often used as the objective function to be optimised for a VQA. On the other hand, for combinatorial problems, and others which do not fall in the realm of real physical systems, the respective problem can be encoded into a Hamiltonian, allowing them to be solved on a quantum computer.o\n",
    "The objective function $f$, defined in terms of an expectation value of a Hamiltonian, can be computed as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\label{eq:general_cost_function}\n",
    "    \\min_{\\bm{\\theta}} f\\left(\\bm{\\theta}, \\left\\{\\langle \\cH \\rangle_{U(\\bm{\\theta})}\\right\\}\\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\langle \\cH \\rangle_{U(\\bm{\\theta})}$ denotes the expectation of the Hamiltonian $\\cH$ in the quantum state generated by the unitary $U(\\bm{\\theta})$, which can be expanded as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle \\cH \\rangle_{U(\\bm{\\theta})} \\equiv \\bra{0}^{\\otimes n}U^\\dagger(\\bm{\\theta}) \\cH U(\\bm{\\theta})\\ket{0}^{\\otimes n}.\n",
    "\\end{equation}\n",
    "\n",
    "Once the Hamiltonian of the problem is determined --- along with the associated objective function --- the next step is to decompose it into a set of operators which are measurable on the quantum device. The most common of which is Pauli string decomposition, where such a decomposed Hamiltonian is given as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathcal{H} = \\sum\\limits_{i=1}^{N} c_i P_i,\n",
    "    \\label{eq:pauli_decomp}\n",
    "\\end{equation}\n",
    "\n",
    "where $c_i$ is the complex coefficient of the $i^\\text{th}$ Pauli string. A Pauli string can be written as tensored Pauli operators $\\sigma^x, \\sigma^y, \\sigma^z$ --- $P = \\bigotimes_{j = 1}^{n} \\sigma$, where $\\sigma \\in \\{I, \\sigma^x, \\sigma^y, \\sigma^z\\}$, with $I$ being the identity operator. As a result, the expectation value of the Hamiltonian can then be measured by evaluating the expectation value of each of the decomposed Pauli strings:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle \\mathcal{H} \\rangle_{U(\\boldsymbol{\\theta})} = \\sum\\limits_{i=1}^{N} c_i \\langle P_i \\rangle_{U(\\boldsymbol{\\theta})}.\n",
    "\\end{equation}\n",
    "\n",
    "The above form of decomposed qubit Hamiltonians include molecules, spin chains, or other encoded models.\n",
    "\n",
    "Other objective functions can also be used, not just Hamiltonian expectation values. In fact, any cost function that can be written in an operational form can be evaluated using a quantum computer, and thus used as an objective function.\n",
    "\n",
    "## Parametrized Quantum Circuit\n",
    "\n",
    "Once the objective function is determined, the next component of the VQA is the quantum circuit that is capable of preparing the quantum state that matches the minimum of the objective function. The quantum state is prepared via a unitary operation that depends on some parameters, that is a PQC.\n",
    "\n",
    "The PQC is generally applied after preparing an initial state $\\ket{\\psi_0}$, such that the quantum state is then\n",
    "\n",
    "\\begin{equation}\n",
    "    \\ket{\\psi(\\boldsymbol{\\theta})} = U(\\boldsymbol{\\theta})\\ket{\\psi_0},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\boldsymbol{\\theta}$ are the variational parameters. Typically, the initial state is simply the all-zero state $\\ket{0}^{\\otimes n} = \\ket{00\\cdots0}$, where $n$ is the number of qubits. However, as an example, the QAOA uses an initial state starting from a uniform superposition of all qubits, such that\n",
    "\n",
    "\\begin{equation}\n",
    "    \\ket{D} = H^{\\otimes n} \\ket{0}^{\\otimes n},\n",
    "    \\label{eq:uniform_superposition}\n",
    "\\end{equation}\n",
    "\n",
    "where $H$ is the Hadamard gate. In quantum chemistry models, the initial state is generally chosen to correspond to the Hartree-Fock approximation. The purpose of preparing a good initial state is so that the algorithm is able to optimise the parameters $\\boldsymbol{\\theta}$ close to an optimal point, helping the overall convergence of the algorithm.\n",
    "\n",
    "Following initial state preparation, the choice of the unitary ansatz $U(\\boldsymbol{\\theta})$ considerably affects the performance of the VQA. A necessary condition to find the optimum is that the quantum state that minimises the objective function is within the Hilbert space of the PQC. However, more complex unitaries generally lead to deeper and non-local circuits, which are more susceptible to errors. As a result, unitary ansatz selection currently falls into two categories, problem-inspired or hardware-efficient, depending on their structure.\n",
    "\n",
    "### Problem-Inspired Ansätze\n",
    "\n",
    "Given a Hermitian operator $g$, one can create a unitary operator describing the evolution of $g$ as a function of time $t$,\n",
    "\n",
    "\\begin{equation}\n",
    "    U(t) = e^{-\\imath g t}.\n",
    "\\end{equation}\n",
    "\n",
    "While $g$ can be any Hermitian operator, such as a Pauli operator, it is often taken to be the Hamiltonian which describes the unitary evolution of the system. Therefore,\n",
    "\n",
    "\\begin{equation}\n",
    "    U(t) = e^{-\\imath \\mathcal{H} t},\n",
    "    \\label{eq:unitary_evolution}\n",
    "\\end{equation}\n",
    "\n",
    "which can be decomposed into Pauli operators as in Eq. \\eqref{eq:pauli_decomp}. However, it is generally not straightforward to employ the unitary given by Eq. \\eqref{eq:unitary_evolution} on a quantum device, and as a consequence, a Suzuki-Trotter decomposition is needed to implement an approximation of the unitary operator. If we once again look at Eq. \\eqref{eq:pauli_decomp}, if the sets of operators $\\left\\{P_i\\right\\}_i$ are chosen such that they are non-commuting, then $e^{-\\imath P_i t}$ can be easily implemented. The full evolution over $t$ of such a decomposition can then be implemented as $k$ equal-sized steps\n",
    "\n",
    "\\begin{equation}\n",
    "    e^{-\\imath \\mathcal{H} t} = \\lim\\limits_{k \\rightarrow \\infty} \\left( \\prod\\limits_i e^{-\\imath \\frac{c_i P_i t}{k}} \\right)^k.\n",
    "\\end{equation}\n",
    "\n",
    "The approximation is then taking $k$ finite steps, such that\n",
    "\n",
    "\\begin{equation}\n",
    "    e^{-\\imath \\mathcal{H} t} \\approx \\left( \\prod\\limits_i e^{-\\imath \\frac{c_i P_i t}{k}} \\right)^k.\n",
    "\\end{equation}\n",
    "\n",
    "This is known as \\textit{trotterisation}, however in practice, this generally results in challenging experimental implementations of such ansätze. Knowledge about the physics of the Hamiltonian can substantially reduce the complexity, depth and number of gates of the PQC using trotterised ansätze. Apart from trotterised ansätze, there is also the unitary coupled cluster (UCC) ansatz, which is derived from quantum chemistry, and is in fact the first ansatz implemented in the VQE.\n",
    "\n",
    "The variational hamiltonian ansatz (VHA) is another ansatz which is motivated by adiabatic state preparation, where it was developed to improve convergence and limit the number of variational parameters. Given a Hamiltonian that is described in a Pauli decomposition as in Eq. \\eqref{eq:pauli_decomp}, then the unitary can be described by\n",
    "\n",
    "\\begin{equation}\n",
    "    U(\\boldsymbol{\\theta}) = \\prod\\limits_i e^{-\\imath \\theta_i P_i},\n",
    "\\end{equation}\n",
    "\n",
    "which can be repeated multiple times in the PQC, corresponding to multiple \\textit{layers} of the unitary operator in the PQC.\n",
    "\n",
    "The QAOA is one of the original algorithms designed to perform well in the NISQ era, to solve combinatorial optimisation problems. While it can be thought of as a type of VQA, it can also be considered as a type of PQC. Given a cost function $C$ that encodes a combinatorial problem in bit strings that form the computational basis vectors $\\ket{i}$, then the problem Hamiltonian $\\mathcal{H}_P$ is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathcal{H}_P \\equiv \\sum\\limits_{i=1}^n C(i)\\ket{i}\\bra{i},\n",
    "\\end{equation}\n",
    "\n",
    "and the mixing Hamiltonian $\\mathcal{H}_M$ as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathcal{H}_M \\equiv \\sum\\limits_{i=1}^n \\sigma_i^x,\n",
    "\\end{equation}\n",
    "\n",
    "with the initial state given as the uniform superposition state $\\ket{D}$ from Eq. \\eqref{eq:uniform_superposition}. The final quantum state is given by alternating unitaries generated by $\\mathcal{H}_P$ and $\\mathcal{H}_M$ on the initial state $p$-times,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\ket{\\psi(\\boldsymbol{\\gamma}, \\boldsymbol{\\beta})} \\equiv e^{-\\imath \\beta_p \\mathcal{H}_M}e^{-\\imath \\gamma_p \\mathcal{H}_P} \\cdots e^{-\\imath \\beta_1 \\mathcal{H}_M}e^{-\\imath \\gamma_1 \\mathcal{H}_P}\\ket{D}.\n",
    "\\end{equation}\n",
    "\n",
    "The cost function is then given by\n",
    "\n",
    "\\begin{equation}\n",
    "    C(\\boldsymbol{\\gamma}, \\boldsymbol{\\beta}) \\equiv \\bra{\\psi(\\boldsymbol{\\gamma}, \\boldsymbol{\\beta})} \\mathcal{H}_P \\ket{\\psi(\\boldsymbol{\\gamma}, \\boldsymbol{\\beta})},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\boldsymbol{\\gamma}$ and $\\boldsymbol{\\beta}$ are the variational parameters. $p$ represents the number of layers of the QAOA. The minimisation at level $p-1$ is a constrained version of the minimisation at level $p$, meaning that the algorithm improves monotonically with $p$.\n",
    "\n",
    "### Hardware-Efficient Ansätze\n",
    "\n",
    "The problem-inspired ansätze are constructed from the underlying physics of the model to be solved. However, given that we are in the NISQ era, we are required to pay more attention to experimental limitations that include qubit connectivity, restricted gate set, decoherence and gate errors, among others. Thus, the concept of hardware-efficient ansätze is then brought forward, with the idea that they respect limited qubit connectivity, with simple and relatively local gates, which are set up to form a sequence of one-qubit gates, followed by an entangling sequence of two-qubit gates. These layers are then repeated enough times to generate a sufficient amount of entanglement and enable the exploration of a large portion of the Hilbert space.\n",
    "\n",
    "A hardware-efficient unitary operator with $L$ layers can be written as\n",
    "\n",
    "\\begin{equation}\n",
    "    U(\\boldsymbol{\\theta}) = \\prod\\limits_{i=k}^L U_k(\\boldsymbol{\\theta}_k)W_k,\n",
    "\\end{equation}\n",
    "\n",
    "where $U_k(\\boldsymbol{\\theta}_k) = \\exp(-\\imath \\boldsymbol{\\theta}_k V_k)$ is a unitary generated by a non-parametrised Hermitian operator $V_k$, typically being one-qubit rotation gates, and $W_k$ is an entangling gate, which is typically non-parametrised. The entangling gate generally depends on the native gate set of the quantum device, for example, for superconducting architectures the typical native two-qubit entangling gate is the CNOT or C$Z$ gate, or $XX$ gates for trapped ions.\n",
    "\n",
    "Instead of deciding whether to use problem-inspired or hardware-efficient ansatz, one can instead find a middle ground.\n",
    "\n",
    "## Measurement Technique\n",
    "\n",
    "A quantum computer can only supply information via measuring quantum states. Typically, the expectation value of a Hamiltonian or operator is required to minimise an objective function. This requires a unitary transformation on the quantum state to the diagonal basis of the Hamiltonian. However, in principle, this is hard to achieve on a NISQ device. The purpose of transforming a Hamiltonian into Pauli strings is because their expectation value can be easily determined on a quantum computer. Typically, the computational basis states $\\ket{0}$ and $\\ket{1}$ can be measured to give the expectation value of the $\\sigma^z$ operator,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle \\sigma^z \\rangle = p_0 - p_1 = 2p_0 - 1,\n",
    "\\end{equation}\n",
    "\n",
    "where $p_0$, $p_1$ are the probabilities to measure the qubit in state $\\ket{0}$, $\\ket{1}$, respectively. The last equality is due to $p_0 + p_1 = 1$. Subsequently, measurements of $\\sigma^x$ and $\\sigma^y$ can be carried out by transforming the operators\n",
    "\\begin{equation}\n",
    "    \\sigma^x = H \\sigma^z H,\n",
    "    \\label{eq:x_transform}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\sigma^y = S H \\sigma^z H S^\\dagger,\n",
    "    \\label{eq:y_transform}\n",
    "\\end{equation}\n",
    "\n",
    "where $S = \\sqrt{\\sigma^z}$ and $H = (\\sigma^x + \\sigma^z)/\\sqrt{2}$ is the Hadamard gate. The expectation values can be determined by applying the transforming gates on the states before measuring in the computational basis, so that\n",
    "\\begin{equation}\n",
    "    \\langle \\sigma^x \\rangle = \\bra{\\psi}\\sigma^x\\ket{\\psi} = \\bra{\\psi}H \\sigma^z H\\ket{\\psi} = 2p_0 - 1,\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle \\sigma^y \\rangle = \\bra{\\psi}\\sigma^y\\ket{\\psi} = \\bra{\\psi}S H \\sigma^z H S^\\dagger\\ket{\\psi} = 2p_0 - 1.\n",
    "\\end{equation}\n",
    "\n",
    "Thus, any Pauli string can be evaluated by, if necessary, transforming each individual qubit $k$ into the $\\sigma^z$ basis, and then measuring:\n",
    "\\begin{align}\n",
    "    \\langle P \\rangle_{U} &= \\left\\langle \\prod\\limits_k \\sigma^{f(k)}(k) \\right\\rangle_U = \\left\\langle \\prod\\limits_k \\sigma^z(k) \\right\\rangle_{VU} = \\prod\\limits_k (2p_0(k) - 1),\n",
    "\\end{align}\n",
    "where $V$ is the product of one-qubit rotations given by Eqs. \\eqref{eq:x_transform} and \\eqref{eq:y_transform}, depending on the Pauli terms $\\sigma^{f(k)}$ at qubit $k$.\n",
    "\n",
    "In many cases, the number of Pauli strings can be so significantly large that it is costly to evaluate each one of them individually. Recently, various approaches that can efficiently measure the expectation value of a Hamiltonian have been proposed, such as grouping different Pauli strings together in such a way that they can be measured simultaneously.\n",
    "\n",
    "Other techniques exist, such as measuring the overlap of a quantum state with a unitary operator, using for example the Hadamard test, or direct implementation techniques. Another method is shadow tomography, which involves measuring the classical shadow of a quantum state to extract the expectation value of observables.\n",
    "\n",
    "## Classical Optimiser\n",
    "\n",
    "Up till now, we have only described the parts of a VQA that run on a quantum device. The final piece is the classical optimisation loop, that produces variational parameter updates to the PQC, tying everything in to create a hybrid quantum--classical algorithm. The specific choice of an optimiser greatly impacts the performance of the VQA. In principle, one can apply any method available in the entire field of multivariate optimisation. However, once again the NISQ era holds us back, since short coherence times prevent the use of analytical gradient circuits, as they are not efficiently implementable, while numerous function evaluations correspond to a significantly long time to calculate the objective function. At the same time, the results from a quantum computer are noisy, both from statistical and quantum device errors, requiring an optimiser that is noise-resistant. As a result, most of the typically used optimisers are not adequate for VQA, and as a result, new optimisation algorithms and techniques are being developed to optimise PQC.\n",
    "\n",
    "Classical optimisers can generally be split into two classes: gradient-based and gradient free. We shall briefly describe the common approaches to both.\n",
    "\n",
    "### Gradient-Based Approach\n",
    "\n",
    "The most common approach to minimise an objective function $f(\\boldsymbol{\\theta})$ is through evaluating its gradient. The gradient of a function indicates the direction in which it exhibits the largest rate of change. Suppose we start at an initial set of $K$ parameters $\\boldsymbol{\\theta}^{(0)}$, and iteratively update $\\boldsymbol{\\theta}^{(t)}$ over steps $t$. One such update rule is\n",
    "\n",
    "\\begin{equation}\n",
    "    \\boldsymbol{\\theta}^{(t+1)} = \\boldsymbol{\\theta}^{(t)} - \\eta \\nabla f(\\boldsymbol{\\theta}),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\eta$ is a hyperparameter, denoted as the learning rate, and $\\nabla = (\\partial_1,\\dots,\\partial_K)$, $\\partial_i \\equiv \\frac{\\partial}{\\partial \\theta_i}$. This translates to optimising each parameter $\\theta_i$ via\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_i^{(t+1)} = \\theta_i^{(t)} - \\eta \\partial_i f(\\boldsymbol{\\theta}),\n",
    "\\end{equation}\n",
    "\n",
    "using Einstein notation. The gradient can be estimated on a quantum computer by using different methods, the most common of which is using finite difference techniques:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\partial_i f(\\boldsymbol{\\theta}) \\approx \\frac{f(\\boldsymbol{\\theta} + \\epsilon \\boldsymbol{e}_i) - f(\\boldsymbol{\\theta} - \\epsilon \\boldsymbol{e}_i)}{2\\epsilon},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\epsilon$ is a small number and $\\boldsymbol{e}_i$ is the unit vector with 1 in its $i^\\text{th}$ element and 0 everywhere else. The smaller the $\\epsilon$, the closer the approximation is to the true value of the gradient. On the other hand, a smaller $\\epsilon$ corresponds to a smaller difference $f(\\boldsymbol{\\theta} + \\epsilon \\boldsymbol{e}_i) - f(\\boldsymbol{\\theta} - \\epsilon \\boldsymbol{e}_i)$, which would in turn entail a larger number of samples from the quantum computer to achieve a good estimation of the gradient}.\n",
    "\n",
    "There are many more techniques used to calculate the gradient of an objective function on a quantum device, such as the parameter-shift rule, quantum natural gradient and stochastic gradient descent. Other techniques that intend to improve convergence include utilising Hessian information for gradient descent, quantum imaginary time evolution and quantum analytic descent.\n",
    "\n",
    "### Gradient-Free Approach\n",
    "\n",
    "One may prefer to employ an optimiser that does not rely on gradient information measured on a quantum computer. There are methods based on evolutionary algorithms, which have been recently applied to VQA, that show comparable performance to gradient-based approaches. Reinforcement learning is another method, originally used to optimise the parameters of QAOA. Surrogate model-based optimisation is an alternative technique to optimise an objective function. It is specifically used when function evaluations are costly to calculate, and so use previous evaluations to inform future iterations of the optimiser.\n",
    "\n",
    "Lastly, sequential minimal optimisation is a technique which will discuss last. Given that all the parameters in a variational circuit are angles, the expectation value of an operator $U$ is sinusoidal in nature, when all but one of the parameters are fixed. As a result, the expectation value can be written as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle U(\\theta) \\rangle = \\alpha \\sin(\\theta + \\beta) + \\gamma,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$, $\\beta$ and $\\gamma$ are parameters than can be determined analytically. This implies that only three specifically chosen circuit evaluations are necessary for determining these parameters, so that the optimal parameter $\\theta^*$ of the parameter $\\theta$ is given by\n",
    "\\begin{equation}\n",
    "    \\theta^* = -\\arctan\\!2 \\left( 2\\left\\langle U\\left( \\phi \\right) \\right\\rangle - \\left\\langle U\\left( \\phi + \\frac{\\pi}{2} \\right) \\right\\rangle - \\left\\langle U\\left( \\phi - \\frac{\\pi}{2} \\right) \\right\\rangle, \\left\\langle U\\left( \\phi + \\frac{\\pi}{2} \\right) \\right\\rangle - \\left\\langle U\\left( \\phi - \\frac{\\pi}{2} \\right) \\right\\rangle\n",
    "    \\right) + 2\\pi k - \\phi -\\frac{\\pi}{2},\n",
    "\\end{equation}\n",
    "where $\\arctan\\!2$ is the two-argument arctangent and $k$ is any integer, while $\\phi$ is any angle. Selecting $\\phi = 0$ and choosing $k$ such that $\\theta^* \\in (-\\pi, \\pi$ is usually the most straightforward choice. The algorithm then proceeds by looping over all the variational parameters $\\boldsymbol{\\theta}$ until convergence is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
